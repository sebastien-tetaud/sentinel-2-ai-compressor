{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder Visualization and Analysis\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading the trained model and extracting just the decoder part\n",
    "2. Loading the saved bottleneck tensor from inference results\n",
    "3. Passing the bottleneck through the decoder\n",
    "4. Visualizing the decoder outputs and analyzing the reconstruction process\n",
    "\n",
    "## Overview\n",
    "- **Input**: Bottleneck tensor from encoder (compressed representation)\n",
    "- **Process**: Decoder-only inference (upsampling and reconstruction)\n",
    "- **Output**: Reconstructed spectral bands with detailed visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Project imports\n",
    "sys.path.append('../')\n",
    "from model_zoo.models import define_model\n",
    "from utils.utils import load_config\n",
    "\n",
    "# Configure display\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Path verification:\n",
      "Config exists: True\n",
      "Checkpoint dir exists: True\n",
      "Bottleneck file exists: True\n"
     ]
    }
   ],
   "source": [
    "# Configuration paths\n",
    "result_path = \"/home/ubuntu/project/sentinel-2-ai-compressor/src/results/2025-08-19_22-18-59\"\n",
    "checkpoint_path = f\"{result_path}/checkpoints\"\n",
    "config_path = f\"{result_path}/config.yaml\"\n",
    "\n",
    "# Data paths\n",
    "inference_results_dir = \"/home/ubuntu/project/sentinel-2-ai-compressor/src/inference_results\"\n",
    "bottleneck_path = f\"/home/ubuntu/project/sentinel-2-ai-compressor/src/inference_results/_bottleneck.pt\"\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Verify paths exist\n",
    "print(f\"\\nPath verification:\")\n",
    "print(f\"Config exists: {os.path.exists(config_path)}\")\n",
    "print(f\"Checkpoint dir exists: {os.path.exists(checkpoint_path)}\")\n",
    "print(f\"Bottleneck file exists: {os.path.exists(bottleneck_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Model Configuration and Extract Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configuration:\n",
      "Model: Unet\n",
      "Encoder: timm-efficientnet-b2\n",
      "Input channels: 11\n",
      "Output channels: 11\n",
      "Activation: relu\n",
      "Bands: ['b01', 'b02', 'b03', 'b04', 'b05', 'b06', 'b07', 'b09', 'b11', 'b12', 'b8a']\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config = load_config(config_path)\n",
    "\n",
    "print(\"Model Configuration:\")\n",
    "print(f\"Model: {config['MODEL']['model_name']}\")\n",
    "print(f\"Encoder: {config['MODEL']['encoder_name']}\")\n",
    "print(f\"Input channels: {len(config['DATASET']['bands'])}\")\n",
    "print(f\"Output channels: {len(config['DATASET']['bands'])}\")\n",
    "print(f\"Activation: {config['MODEL']['activation']}\")\n",
    "print(f\"Bands: {config['DATASET']['bands']}\")\n",
    "\n",
    "bands = config['DATASET']['bands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model weights...\n",
      "Full model loaded successfully!\n",
      "Model architecture: Sequential\n"
     ]
    }
   ],
   "source": [
    "# Initialize full model\n",
    "full_model = define_model(\n",
    "    name=config['MODEL']['model_name'],\n",
    "    encoder_name=config['MODEL']['encoder_name'],\n",
    "    encoder_weights=config['MODEL']['encoder_weights'],\n",
    "    in_channel=len(config['DATASET']['bands']),\n",
    "    out_channels=len(config['DATASET']['bands']),\n",
    "    activation=config['MODEL']['activation']\n",
    ")\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading trained model weights...\")\n",
    "full_model.load_state_dict(torch.load(os.path.join(checkpoint_path, \"best_model.pth\")))\n",
    "full_model = full_model.to(device)\n",
    "full_model.eval()\n",
    "\n",
    "print(f\"Full model loaded successfully!\")\n",
    "print(f\"Model architecture: {type(full_model).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Bottleneck Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bottleneck tensor...\n",
      "Bottleneck tensor loaded successfully!\n",
      "Bottleneck shape: torch.Size([36, 208, 10, 10])\n",
      "Bottleneck dtype: torch.float32\n",
      "Bottleneck device: cuda:0\n",
      "Memory size: 2.86 MB\n",
      "\n",
      "Bottleneck Statistics:\n",
      "Mean: -0.128684\n",
      "Std: 6.212026\n",
      "Min: -115.062149\n",
      "Max: 122.589828\n"
     ]
    }
   ],
   "source": [
    "# Load the bottleneck tensor\n",
    "print(\"Loading bottleneck tensor...\")\n",
    "bottleneck_tensor = torch.load(bottleneck_path, map_location=device)\n",
    "\n",
    "print(f\"Bottleneck tensor loaded successfully!\")\n",
    "print(f\"Bottleneck shape: {bottleneck_tensor.shape}\")\n",
    "print(f\"Bottleneck dtype: {bottleneck_tensor.dtype}\")\n",
    "print(f\"Bottleneck device: {bottleneck_tensor.device}\")\n",
    "print(f\"Memory size: {bottleneck_tensor.numel() * bottleneck_tensor.element_size() / (1024**2):.2f} MB\")\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nBottleneck Statistics:\")\n",
    "print(f\"Mean: {bottleneck_tensor.mean().item():.6f}\")\n",
    "print(f\"Std: {bottleneck_tensor.std().item():.6f}\")\n",
    "print(f\"Min: {bottleneck_tensor.min().item():.6f}\")\n",
    "print(f\"Max: {bottleneck_tensor.max().item():.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_processor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
