{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124f6c1f",
   "metadata": {},
   "source": [
    "## Zarr DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005368bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import natsort\n",
    "import xarray as xr\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../')\n",
    "from data.healpix import *\n",
    "from utils.plot import plot_all_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa51adcb",
   "metadata": {},
   "source": [
    "The main goal of this Notebook is to create a Datasets and DataLoader that manipulate Zarr and its associated chunks. PyTorch provides two data primitives: torch.utils.data.DataLoader and torch.utils.data.Dataset that allow you to use pre-loaded datasets as well as your own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a959979",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a07345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_paths(path_dir):\n",
    "\n",
    "    df_input = pd.read_csv(f\"{path_dir}/input.csv\")\n",
    "    df_output = pd.read_csv(f\"{path_dir}/target.csv\")\n",
    "    df_input[\"path\"] = df_input[\"Name\"].apply(lambda x: os.path.join(path_dir, \"input\", os.path.basename(x).replace(\".SAFE\",\"\")))\n",
    "    df_output[\"path\"] = df_output[\"Name\"].apply(lambda x: os.path.join(path_dir, \"target\", os.path.basename(x).replace(\".SAFE\",\"\")))\n",
    "\n",
    "    return df_input, df_output\n",
    "\n",
    "base_dir = \"/mnt/disk/dataset/sentinel-ai-processor\"\n",
    "version = \"V4\"\n",
    "\n",
    "TRAIN_DIR = f\"{base_dir}/{version}/train/\"\n",
    "VAL_DIR = f\"{base_dir}/{version}/val/\"\n",
    "TEST_DIR = f\"{base_dir}/{version}/test/\"\n",
    "df_train_input, df_train_output =  prepare_paths(TRAIN_DIR)\n",
    "df_val_input, df_val_output =  prepare_paths(VAL_DIR)\n",
    "df_test_input, df_test_output =  prepare_paths(TEST_DIR)\n",
    "df_test_output = df_test_output[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4b9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02809c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open .zarr datatree\n",
    "x_path = df_test_output[\"path\"].iloc[zarr_index] + \".zarr\"\n",
    "dt = xr.open_datatree(x_path, engine=\"zarr\", mask_and_scale=False, chunks={})\n",
    "x_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2324c952",
   "metadata": {},
   "source": [
    "## Plot all chunks for a given resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f93076",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = \"60m\"\n",
    "band = \"b01\"\n",
    "chunk_size_y, chunk_size_x, nb_chunks_y, nb_chunks_x = get_chunk_info(data_tree=dt, band=band, res=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554cea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_chunks(dt, band, res, chunk_size_y, chunk_size_x, nb_chunks_y, nb_chunks_x, cmap=\"viridis\", verbose= False, figsize_scale=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4206162d",
   "metadata": {},
   "source": [
    "## Extract Chunk from Xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419dbf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_y_idx = 4\n",
    "chunk_x_idx = 4\n",
    "chunk = get_chunk(data_tree=dt, res=res,\n",
    "                  chunk_y_idx=chunk_y_idx, chunk_x_idx=chunk_x_idx,\n",
    "                  chunk_size_y=chunk_size_y, chunk_size_x=chunk_size_x)\n",
    "\n",
    "chunk_array = chunk.to_dataset().to_dataarray()\n",
    "chunk_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b97f9c",
   "metadata": {},
   "source": [
    "## Datasets & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff28352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --------- Sentinel2 Dataset ----------\n",
    "class Sentinel2ZarrDataset(Dataset):\n",
    "    def __init__(self, df_x, res, bands):\n",
    "        self.df_x = df_x\n",
    "        self.res_key = f\"r{res}\"\n",
    "        self.x_res = f\"x_{res}\"\n",
    "        self.y_res = f\"y_{res}\"\n",
    "        self.bands = bands\n",
    "        self.res = res\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x_path = self.df_x[\"path\"].iloc[index] + \".zarr\"\n",
    "        dt = xr.open_datatree(x_path, engine=\"zarr\", mask_and_scale=False, chunks={})\n",
    "        data_tree = dt.measurements.reflectance[self.res_key]\n",
    "\n",
    "        chunk_size_y = data_tree[\"b01\"].chunksizes[self.y_res][0]\n",
    "        chunk_size_x = data_tree[\"b01\"].chunksizes[self.x_res][0]\n",
    "        nb_chunks_y = len(data_tree[\"b01\"].chunksizes[self.y_res])\n",
    "        nb_chunks_x = len(data_tree[\"b01\"].chunksizes[self.x_res])\n",
    "\n",
    "        all_chunks = []\n",
    "        for row in range(nb_chunks_y):  # matrix row = Y\n",
    "            for col in range(nb_chunks_x):  # matrix col = X\n",
    "                y_start = row * chunk_size_y\n",
    "                x_start = col * chunk_size_x\n",
    "                chunk = data_tree.isel(\n",
    "                    {self.y_res: slice(y_start, y_start + chunk_size_y),\n",
    "                     self.x_res: slice(x_start, x_start + chunk_size_x)}\n",
    "                )\n",
    "                chunk = np.array(chunk.load().to_dataset().to_dataarray())\n",
    "                chunk = torch.from_numpy(chunk)\n",
    "                all_chunks.append(chunk)\n",
    "\n",
    "        all_chunks = torch.stack(all_chunks)  # [nb_chunks, bands, h, w]\n",
    "        all_chunks = all_chunks.view(nb_chunks_y, nb_chunks_x, *all_chunks.shape[1:])\n",
    "        return all_chunks, (nb_chunks_y, nb_chunks_x, chunk_size_y, chunk_size_x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e29524",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be903a",
   "metadata": {},
   "source": [
    "Total batch number is equal to Number of zarr * nb_chunks_x * nb_chunks_y\n",
    "\n",
    "example: \n",
    " - 60m resolution\n",
    " - nb_chunks_x = 6 \n",
    " - nb_chunks_y = 6 \n",
    " - batch_size in train_loader = 2\n",
    "\n",
    "final batch = batch_size* nb_chunks_x * nb_chunks_y * = 72\n",
    "\n",
    "Final ouput ->>>>  [72, 11, 305, 305]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f0b311",
   "metadata": {},
   "source": [
    "## Check data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f219f2f",
   "metadata": {},
   "source": [
    "Let's take a random index in the entire dataset. batch = len of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d70e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# --------- Parameters ----------\n",
    "res = \"60m\"\n",
    "bands = ['b01', 'b02', 'b03', 'b04', 'b05', 'b06', 'b07', 'b09', 'b11', 'b12', 'b8a']\n",
    "batch_size = 2\n",
    "\n",
    "train_dataset = Sentinel2ZarrDataset(df_x=df_test_output, res=res, bands=bands)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "with tqdm(total=len(train_loader.dataset), ncols=100, colour='#3eedc4') as t:\n",
    "\n",
    "    t.set_description(\"Training\")\n",
    "    for chunks_grid, _ in train_loader:\n",
    "        # chunks_grid: [B, nb_chunks_y, nb_chunks_x, C, H, W]\n",
    "        # Flatten chunk grid â†’ [B * nb_chunks_y * nb_chunks_x, C, H, W]\n",
    "        B, ny, nx, C, H, W = chunks_grid.shape\n",
    "        chunks_tensor = chunks_grid.view(B * ny * nx, C, H, W).to(device)\n",
    "        print(chunks_tensor.shape)\n",
    "        t.update(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56da482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final output shape {chunks_tensor.shape} - [B, C, H, W]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941dc975",
   "metadata": {},
   "source": [
    "# Batch Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a076aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b5eacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = \"60m\"\n",
    "bands = ['b01', 'b02', 'b03', 'b04', 'b05', 'b06', 'b07', 'b09', 'b11', 'b12', 'b8a']\n",
    "df_test_input, df_test_output =  prepare_paths(TEST_DIR)\n",
    "batch_size = len(df_test_output)\n",
    "train_dataset = Sentinel2ZarrDataset(df_x=df_test_output, res=res, bands=bands)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "with tqdm(total=len(train_loader.dataset), ncols=100, colour='#3eedc4') as t:\n",
    "    t.set_description(\"Training\")\n",
    "\n",
    "    for batch_idx, (chunks_grid, _) in enumerate(train_loader):\n",
    "        # chunks_grid: [B, nb_chunks_y, nb_chunks_x, C, H, W]\n",
    "        B, ny, nx, C, H, W = chunks_grid.shape\n",
    "        chunks_tensor = chunks_grid.view(B * ny * nx, C, H, W).to(device)\n",
    "\n",
    "        print(chunks_tensor.shape)\n",
    "\n",
    "        # Loop over each scene in the batch\n",
    "        for batch_scene in range(B):\n",
    "            scene_index = batch_idx * batch_size + batch_scene\n",
    "            scene_chunks = chunks_grid[batch_scene]  # [ny, nx, C, H, W]\n",
    "\n",
    "            # Pick a position in the chunk grid\n",
    "            row_idx = 0\n",
    "            col_idx = 4\n",
    "\n",
    "            # Get rebuilt chunk from dataset tensor\n",
    "            rebuilt_chunk = scene_chunks[row_idx, col_idx]  # [C, H, W]\n",
    "\n",
    "            # Load same chunk directly from Zarr\n",
    "            x_path = df_test_output[\"path\"].iloc[scene_index] + \".zarr\"\n",
    "            dt = xr.open_datatree(x_path, engine=\"zarr\", mask_and_scale=False, chunks={})\n",
    "            data_tree = dt.measurements.reflectance[f\"r{res}\"]\n",
    "\n",
    "            # Compute pixel indices in full image\n",
    "            chunk_size_y = H\n",
    "            chunk_size_x = W\n",
    "            y_start = row_idx * chunk_size_y\n",
    "            x_start = col_idx * chunk_size_x\n",
    "\n",
    "            original_chunk = data_tree.isel(\n",
    "                {f\"y_{res}\": slice(y_start, y_start + chunk_size_y),\n",
    "                 f\"x_{res}\": slice(x_start, x_start + chunk_size_x)}\n",
    "            ).to_dataset().to_dataarray()\n",
    "\n",
    "            # --- Plot rebuilt ---\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.imshow(rebuilt_chunk[0].cpu().numpy(), cmap=\"viridis\")\n",
    "            plt.title(f\"Rebuilt - Scene {scene_index} - Chunk ({row_idx}, {col_idx}) - Band 0\")\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "\n",
    "            # --- Plot original ---\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.imshow(original_chunk[0].values, cmap=\"viridis\")\n",
    "            plt.title(f\"Original - Scene {scene_index} - Chunk ({row_idx}, {col_idx}) - Band 0\")\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "\n",
    "        t.update(B)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_processor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
