{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124f6c1f",
   "metadata": {},
   "source": [
    "## Zarr DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005368bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import natsort\n",
    "import xarray as xr\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('../')\n",
    "from data.healpix import *\n",
    "from utils.plot import plot_all_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa51adcb",
   "metadata": {},
   "source": [
    "The main goal of this Notebook is to create a Datasets and DataLoader that manipulate Zarr and its associated chunks. PyTorch provides two data primitives: torch.utils.data.DataLoader and torch.utils.data.Dataset that allow you to use pre-loaded datasets as well as your own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a959979",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a07345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_paths(path_dir):\n",
    "\n",
    "    df_input = pd.read_csv(f\"{path_dir}/input.csv\")\n",
    "    df_output = pd.read_csv(f\"{path_dir}/target.csv\")\n",
    "    df_input[\"path\"] = df_input[\"Name\"].apply(lambda x: os.path.join(path_dir, \"input\", os.path.basename(x).replace(\".SAFE\",\"\")))\n",
    "    df_output[\"path\"] = df_output[\"Name\"].apply(lambda x: os.path.join(path_dir, \"target\", os.path.basename(x).replace(\".SAFE\",\"\")))\n",
    "\n",
    "    return df_input, df_output\n",
    "\n",
    "base_dir = \"/mnt/disk/dataset/sentinel-ai-processor\"\n",
    "version = \"V4\"\n",
    "\n",
    "TRAIN_DIR = f\"{base_dir}/{version}/train/\"\n",
    "VAL_DIR = f\"{base_dir}/{version}/val/\"\n",
    "TEST_DIR = f\"{base_dir}/{version}/test/\"\n",
    "df_train_input, df_train_output =  prepare_paths(TRAIN_DIR)\n",
    "df_val_input, df_val_output =  prepare_paths(VAL_DIR)\n",
    "df_test_input, df_test_output =  prepare_paths(TEST_DIR)\n",
    "df_test_output = df_test_output[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4b9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02809c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open .zarr datatree\n",
    "x_path = df_train_output[\"path\"].iloc[zarr_index] + \".zarr\"\n",
    "dt = xr.open_datatree(x_path, engine=\"zarr\", chunks={}, decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed8360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6af8da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2324c952",
   "metadata": {},
   "source": [
    "## Plot all chunks for a given resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f93076",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = \"60m\"\n",
    "bands = get_bands(data_tree=dt, res=res)\n",
    "bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size_y, chunk_size_x, nb_chunks_y, nb_chunks_x = get_chunk_info(data_tree=dt, band=bands[0], res=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554cea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for band in bands:\n",
    "#     plot_all_chunks(dt  , band, res, chunk_size_y, chunk_size_x, nb_chunks_y, nb_chunks_x, save=True, filename=band ,  cmap=\"viridis\", verbose= False, figsize_scale=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4206162d",
   "metadata": {},
   "source": [
    "## Extract Chunk from Xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419dbf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_y_idx = 4\n",
    "chunk_x_idx = 4\n",
    "chunk = get_chunk(data_tree=dt, res=res,\n",
    "                  chunk_y_idx=chunk_y_idx, chunk_x_idx=chunk_x_idx,\n",
    "                  chunk_size_y=chunk_size_y, chunk_size_x=chunk_size_x)\n",
    "\n",
    "chunk_array = chunk.to_dataset().to_dataarray()\n",
    "chunk_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b97f9c",
   "metadata": {},
   "source": [
    "## Datasets & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff28352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Sentinel2ZarrDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads Sentinel-2 data stored in Zarr format and returns all chunks for a scene.\n",
    "\n",
    "    Returns:\n",
    "        chunks_grid: Tensor of shape [nb_chunks_y, nb_chunks_x, bands, H, W]\n",
    "        meta: Tuple (nb_chunks_y, nb_chunks_x, chunk_size_y, chunk_size_x)\n",
    "    \"\"\"\n",
    "    def __init__(self, df_x, res, bands):\n",
    "        self.df_x = df_x\n",
    "        self.res = res\n",
    "        self.bands = bands\n",
    "\n",
    "        self.res_key = f\"r{res}\"\n",
    "        self.x_res = f\"x_{res}\"\n",
    "        self.y_res = f\"y_{res}\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # --- Open Zarr scene ---\n",
    "        zarr_path = self.df_x[\"path\"].iloc[index] + \".zarr\"\n",
    "        datatree = xr.open_datatree(zarr_path, engine=\"zarr\", mask_and_scale=False, chunks={})\n",
    "        data = datatree.measurements.reflectance[self.res_key]\n",
    "\n",
    "        data = data.to_dataset()\n",
    "        data = data[bands].to_dataarray()\n",
    "        # --- Get chunk layout ---\n",
    "        band  = self.bands[0]\n",
    "        chunk_size_y = data.chunksizes[self.y_res][0]\n",
    "        chunk_size_x = data.chunksizes[self.x_res][0]\n",
    "        nb_chunks_y = len(data.chunksizes[self.y_res])\n",
    "        nb_chunks_x = len(data.chunksizes[self.x_res])\n",
    "\n",
    "        # --- Collect all chunks ---\n",
    "        all_chunks = []\n",
    "        for row in range(nb_chunks_y):  # Y direction\n",
    "            for col in range(nb_chunks_x):  # X direction\n",
    "                y_start = row * chunk_size_y\n",
    "                x_start = col * chunk_size_x\n",
    "                chunk_ds = data.isel(\n",
    "                            {self.y_res: slice(y_start, y_start + chunk_size_y),\n",
    "                            self.x_res: slice(x_start, x_start + chunk_size_x)}\n",
    "                        )\n",
    "\n",
    "                chunk_array = chunk_ds.values.astype(np.float32)\n",
    "                chunk_tensor = torch.from_numpy(chunk_array)\n",
    "                all_chunks.append(chunk_tensor)\n",
    "\n",
    "        # --- Stack into [nb_chunks_y, nb_chunks_x, bands, H, W] ---\n",
    "        all_chunks = torch.stack(all_chunks)\n",
    "        chunks_grid = all_chunks.view(nb_chunks_y, nb_chunks_x, *all_chunks.shape[1:])\n",
    "\n",
    "        meta = (nb_chunks_y, nb_chunks_x, chunk_size_y, chunk_size_x)\n",
    "        return chunks_grid, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e29524",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be903a",
   "metadata": {},
   "source": [
    "Total batch number is equal to Number of zarr * nb_chunks_x * nb_chunks_y\n",
    "\n",
    "example: \n",
    " - 60m resolution\n",
    " - nb_chunks_x = 6 \n",
    " - nb_chunks_y = 6 \n",
    " - batch_size in train_loader = 2\n",
    "\n",
    "final batch = batch_size* nb_chunks_x * nb_chunks_y * = 72\n",
    "\n",
    "Final ouput ->>>>  [72, 11, 305, 305]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f0b311",
   "metadata": {},
   "source": [
    "## Check data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f219f2f",
   "metadata": {},
   "source": [
    "Let's take a random index in the entire dataset. batch = len of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d70e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# --------- Parameters ----------\n",
    "res = \"60m\"\n",
    "bands = ['b01', 'b02', 'b03', 'b04', 'b05', 'b06', 'b07', 'b09', 'b11', 'b12', 'b8a']\n",
    "batch_size = 2\n",
    "\n",
    "train_dataset = Sentinel2ZarrDataset(df_x=df_test_output, res=res, bands=bands)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "with tqdm(total=len(train_loader.dataset), ncols=100, colour='#3eedc4') as t:\n",
    "\n",
    "    t.set_description(\"Training\")\n",
    "    for chunks_grid, _ in train_loader:\n",
    "        # chunks_grid: [B, nb_chunks_y, nb_chunks_x, C, H, W]\n",
    "        # Flatten chunk grid â†’ [B * nb_chunks_y * nb_chunks_x, C, H, W]\n",
    "        B, ny, nx, C, H, W = chunks_grid.shape\n",
    "        chunks_tensor = chunks_grid.view(B * ny * nx, C, H, W).to(device)\n",
    "        print(chunks_tensor.shape)\n",
    "        t.update(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56da482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final output shape {chunks_tensor.shape} - [B, C, H, W]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941dc975",
   "metadata": {},
   "source": [
    "# Batch Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a076aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b5eacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = \"60m\"\n",
    "bands = ['b01', 'b02', 'b03', 'b04', 'b05', 'b06', 'b07', 'b09', 'b11', 'b12', 'b8a']\n",
    "df_test_input, df_test_output =  prepare_paths(TEST_DIR)\n",
    "batch_size = len(df_test_output)\n",
    "train_dataset = Sentinel2ZarrDataset(df_x=df_test_output, res=res, bands=bands)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "with tqdm(total=len(train_loader.dataset), ncols=100, colour='#3eedc4') as t:\n",
    "    t.set_description(\"Training\")\n",
    "\n",
    "    for batch_idx, (chunks_grid, _) in enumerate(train_loader):\n",
    "        # chunks_grid: [B, nb_chunks_y, nb_chunks_x, C, H, W]\n",
    "        B, ny, nx, C, H, W = chunks_grid.shape\n",
    "        chunks_tensor = chunks_grid.view(B * ny * nx, C, H, W).to(device)\n",
    "\n",
    "        print(chunks_tensor.shape)\n",
    "\n",
    "        # Loop over each scene in the batch\n",
    "        for batch_scene in range(B):\n",
    "            scene_index = batch_idx * batch_size + batch_scene\n",
    "            scene_chunks = chunks_grid[batch_scene]  # [ny, nx, C, H, W]\n",
    "\n",
    "            # Pick a position in the chunk grid\n",
    "            row_idx = 0\n",
    "            col_idx = 4\n",
    "\n",
    "            # Get rebuilt chunk from dataset tensor\n",
    "            rebuilt_chunk = scene_chunks[row_idx, col_idx]  # [C, H, W]\n",
    "\n",
    "            # Load same chunk directly from Zarr\n",
    "            x_path = df_test_output[\"path\"].iloc[scene_index] + \".zarr\"\n",
    "            dt = xr.open_datatree(x_path, engine=\"zarr\", mask_and_scale=False, chunks={})\n",
    "            data_tree = dt.measurements.reflectance[f\"r{res}\"]\n",
    "\n",
    "            # Compute pixel indices in full image\n",
    "            chunk_size_y = H\n",
    "            chunk_size_x = W\n",
    "            y_start = row_idx * chunk_size_y\n",
    "            x_start = col_idx * chunk_size_x\n",
    "\n",
    "            original_chunk = data_tree.isel(\n",
    "                {f\"y_{res}\": slice(y_start, y_start + chunk_size_y),\n",
    "                 f\"x_{res}\": slice(x_start, x_start + chunk_size_x)}\n",
    "            ).to_dataset().to_dataarray()\n",
    "\n",
    "            # --- Plot rebuilt ---\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.imshow(rebuilt_chunk[0].cpu().numpy(), cmap=\"viridis\")\n",
    "            plt.title(f\"Rebuilt - Scene {scene_index} - Chunk ({row_idx}, {col_idx}) - Band 0\")\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "\n",
    "            # --- Plot original ---\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.imshow(original_chunk[0].values, cmap=\"viridis\")\n",
    "            plt.title(f\"Original - Scene {scene_index} - Chunk ({row_idx}, {col_idx}) - Band 0\")\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "            break\n",
    "\n",
    "        t.update(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046c2f7d",
   "metadata": {},
   "source": [
    "## DataLoader With Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a87cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# ---------------- Normalization ----------------\n",
    "def normalize(data_array):\n",
    "    normalized_data = []\n",
    "    valid_masks = []\n",
    "    for i in range(data_array.shape[2]):\n",
    "        band_data = data_array[:, :, i]\n",
    "        valid_mask = (band_data > 0)\n",
    "        result = band_data.copy().astype(np.float32)\n",
    "        result[~valid_mask] = 0.0\n",
    "        normalized_data.append(result)\n",
    "        valid_masks.append(valid_mask)\n",
    "    return np.dstack(normalized_data), np.dstack(valid_masks)\n",
    "\n",
    "class Sentinel2ZarrDataset(Dataset):\n",
    "    def __init__(self, df_x, res, bands, target_size=(320, 320)):\n",
    "        self.df_x = df_x\n",
    "        self.res = res\n",
    "        self.bands = bands\n",
    "        self.target_size = target_size\n",
    "        self.res_key = f\"r{res}\"\n",
    "        self.x_res = f\"x_{res}\"\n",
    "        self.y_res = f\"y_{res}\"\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        zarr_path = self.df_x[\"path\"].iloc[index] + \".zarr\"\n",
    "        datatree = xr.open_datatree(zarr_path, engine=\"zarr\", mask_and_scale=False)\n",
    "        data = datatree.measurements.reflectance[self.res_key]\n",
    "        data = data.to_dataset()\n",
    "        data = data[self.bands].to_dataarray()\n",
    "\n",
    "        # --- Get chunk layout ---\n",
    "        band  = self.bands[0]\n",
    "        chunk_size_y = data.chunksizes[self.y_res][0]\n",
    "        chunk_size_x = data.chunksizes[self.x_res][0]\n",
    "        nb_chunks_y = len(data.chunksizes[self.y_res])\n",
    "        nb_chunks_x = len(data.chunksizes[self.x_res])\n",
    "\n",
    "        all_chunks, all_masks = [], []\n",
    "\n",
    "        for row in range(nb_chunks_y):  # Y direction\n",
    "            for col in range(nb_chunks_x):  # X direction\n",
    "                y_start = row * chunk_size_y\n",
    "                x_start = col * chunk_size_x\n",
    "                chunk_ds = data.isel(\n",
    "                            {self.y_res: slice(y_start, y_start + chunk_size_y),\n",
    "                            self.x_res: slice(x_start, x_start + chunk_size_x)}\n",
    "                        )\n",
    "                chunk_array = chunk_ds.values.astype(np.float32)\n",
    "                chunk_array, mask_array = normalize(chunk_array)\n",
    "\n",
    "                # Convert to torch [C, H, W]\n",
    "                chunk_tensor = torch.from_numpy(chunk_array).float()\n",
    "                mask_tensor = torch.from_numpy(mask_array).float()\n",
    "\n",
    "                all_chunks.append(chunk_tensor)\n",
    "                all_masks.append(mask_tensor)\n",
    "\n",
    "        chunks_grid = torch.stack(all_chunks).view(nb_chunks_y, nb_chunks_x, *all_chunks[0].shape)\n",
    "        masks_grid = torch.stack(all_masks).view(nb_chunks_y, nb_chunks_x, *all_masks[0].shape)\n",
    "        meta = (nb_chunks_y, nb_chunks_x, chunk_size_y, chunk_size_x)\n",
    "\n",
    "        datatree.close()\n",
    "        return chunks_grid, masks_grid, meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9228d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "res = \"60m\"\n",
    "bands = ['b01','b02','b03','b04','b05','b06','b07','b09','b11','b12','b8a']\n",
    "batch_size = 2\n",
    "\n",
    "dataset = Sentinel2ZarrDataset(df_x=df_test_output, res=res, bands=bands)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "with tqdm(total=len(loader.dataset), ncols=100, colour='#3eedc4') as t:\n",
    "    t.set_description(\"Processing\")\n",
    "    for chunks_grid, masks_grid, meta in loader:\n",
    "        B, ny, nx, C, H, W = chunks_grid.shape\n",
    "        chunks_tensor = chunks_grid.view(B*ny*nx, C, H, W).to(device)\n",
    "        masks_tensor = masks_grid.view(B*ny*nx, C, H, W).to(device)\n",
    "        t.update(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354af9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a01d0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Parameters ----------------\n",
    "res = \"60m\"\n",
    "bands = get_bands(data_tree=dt, res=res)\n",
    "df_test_input, df_test_output = prepare_paths(TEST_DIR)\n",
    "batch_size = len(df_test_output)\n",
    "\n",
    "train_dataset = Sentinel2ZarrDataset(df_x=df_test_output, res=res, bands=bands,target_size=(320,320) )\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0333411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Loop over dataset ----------------\n",
    "with tqdm(total=len(train_loader.dataset), ncols=100, colour='#3eedc4') as t:\n",
    "    t.set_description(\"Processing\")\n",
    "    for batch_idx, (chunks_grid, masks_grid, meta) in enumerate(train_loader):\n",
    "        B, ny, nx, C, H, W = chunks_grid.shape\n",
    "        chunks_tensor = chunks_grid.view(B*ny*nx, C, H, W).to(device)\n",
    "        masks_tensor = masks_grid.view(B*ny*nx, C, H, W).to(device)\n",
    "\n",
    "        for batch_scene in range(B):\n",
    "            scene_index = batch_idx * batch_size + batch_scene\n",
    "            scene_chunks = chunks_grid[batch_scene]  # [ny, nx, C, H, W]\n",
    "\n",
    "            row_idx, col_idx = 0, 4\n",
    "            rebuilt_chunk = scene_chunks[row_idx, col_idx]  # [C, H, W]\n",
    "            # Load same chunk from Zarr\n",
    "            x_path = df_test_output[\"path\"].iloc[scene_index] + \".zarr\"\n",
    "            dt = xr.open_datatree(x_path, engine=\"zarr\", mask_and_scale=False, chunks={})\n",
    "            data_tree = dt.measurements.reflectance[f\"r{res}\"]\n",
    "\n",
    "            y_start, x_start = row_idx * H, col_idx * W\n",
    "            original_chunk = data_tree.isel(\n",
    "                {f\"y_{res}\": slice(y_start, y_start + H),\n",
    "                 f\"x_{res}\": slice(x_start, x_start + W)}\n",
    "            ).to_dataset().to_dataarray()\n",
    "\n",
    "            # ---------------- Plot ----------------\n",
    "            plt.figure(figsize=(8,6))\n",
    "            plt.imshow(rebuilt_chunk[0].cpu().numpy(), cmap=\"viridis\")\n",
    "            plt.title(f\"Rebuilt - Scene {scene_index} - Chunk ({row_idx},{col_idx}) - Band 0\")\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "\n",
    "            plt.figure(figsize=(8,6))\n",
    "            plt.imshow(original_chunk[0].values, cmap=\"viridis\")\n",
    "            plt.title(f\"Original - Scene {scene_index} - Chunk ({row_idx},{col_idx}) - Band 0\")\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "            break\n",
    "        t.update(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8c72db",
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_processor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
